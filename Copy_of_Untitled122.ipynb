{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyamlakra/Deep-learning/blob/main/Copy_of_Untitled122.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7QCbDA3cTnX",
        "outputId": "5a181359-7cae-4674-9a30-60f5a3dd77bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb  2 09:57:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-AmO_xB6nml"
      },
      "outputs": [],
      "source": [
        "!pcie_aspm=force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21-VrJTklQ_t",
        "outputId": "e2d37737-e18c-44c1-8021-37162be80cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 23 kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.43.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=359591362c9acd7d79871c76763fc4eb4f42155d8a8d3563af659ad084ad1373\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 4.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 74.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.5 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U segmentation-models\n",
        "!pip install segmentation-models\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install pickle5\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "A4vuGglpMqAZ",
        "outputId": "fe8db84a-c0bf-41bb-a22f-5c709111c762"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b17801ec-1fb9-42ef-924d-79eeb39d5fc9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b17801ec-1fb9-42ef-924d-79eeb39d5fc9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"satyamlakra\",\"key\":\"0251af1af0a2ddc2fac655b8a7ba4dc0\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0eqL2A9PEhP"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8jlqilaP02u"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrxubhA2P7U-"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCZ5f3XvQMcO"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_GliQF6LYbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e051c2-4293-4ca6-c1be-7747c4c55a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mapillaryvistasval.zip to /content\n",
            " 99% 2.33G/2.35G [01:19<00:00, 29.2MB/s]\n",
            "100% 2.35G/2.35G [01:19<00:00, 31.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d pengweili/mapillaryvistasval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O5-WkeVRlCb",
        "outputId": "f94b63cc-ed0c-4d74-ca49-2d602e06ac90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading berkely-deep-drive.zip to /content\n",
            " 99% 2.07G/2.09G [01:00<00:00, 20.8MB/s]\n",
            "100% 2.09G/2.09G [01:00<00:00, 36.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d liammcgunnigle/berkely-deep-drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0N0CuxJZWnw"
      },
      "outputs": [],
      "source": [
        "! unzip berkely-deep-drive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leYi5PMrUQAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9809de32-7d44-4e6d-a590-84c9f791095e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/GDrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/GDrive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMU-Dija_eTs"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons==0.8.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwleWJtdQ4UR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Activation,UpSampling2D,Input,Reshape,BatchNormalization\n",
        "#import tensorflow_addons as tfa\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import image as img\n",
        "import pickle5 as pickle\n",
        "from tensorflow import  keras\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#import tensorflow_model_optimization as tfmot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-R6gLMvGS2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7735775c-7501-4504-c057-a4fb31b50670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[131, 142, 70, 70, 70, 70, 42] 5\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]] 5\n"
          ]
        }
      ],
      "source": [
        "# Initializing Input vector\n",
        "\n",
        "class_vector =[131 , 142 ,70, 70, 70, 70 ,42 ]\n",
        "print(class_vector,len(np.unique(class_vector))+1)\n",
        "tf.compat.v1.disable_eager_execution() \n",
        "# Applying the function on input class vector\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "o = to_categorical(class_vector, dtype =\"uint8\")\n",
        "print(o , len(np.unique(class_vector))+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMj91_7qsfvE",
        "outputId": "a75e5b25-f6d4-4a1b-aea6-ad500045236c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 143)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDT1B8VLGbyE"
      },
      "outputs": [],
      "source": [
        "l= '2008_003429.png'\n",
        "l=l.replace(\"png\", \"jpg\")\n",
        "print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qIJ6lpEn2_i"
      },
      "outputs": [],
      "source": [
        "def dax(x):\n",
        "    lower_blue=np.array([250,250,250])\n",
        "    upper_blue=np.array([255,255,255])\n",
        "     \n",
        "    mask1 = cv2.inRange(x, lower_blue, upper_blue) \n",
        "  \n",
        "    mas = mask1\n",
        "    mask = cv2.bitwise_and(x,x, mask=mas)\n",
        "    mask[mask1!=0]=(60,10,221)\n",
        "   \n",
        "    return np.array(mask, dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCTqaxiDQ4UX"
      },
      "outputs": [],
      "source": [
        "p =['train']\n",
        "p1=['train']\n",
        "gh=256\n",
        "a=[]\n",
        "t=[]\n",
        "r=[]\n",
        "aa=[]\n",
        "dirs='/content/images/images'\n",
        "dirss='/content/color_labels/color_labels'\n",
        "for i in  p:\n",
        "    e=os.path.join(dirs,i)\n",
        "    \n",
        "    for j in os.listdir(e):\n",
        "        pa=os.path.join(e,j)\n",
        "        t.append(pa)\n",
        "   \n",
        "t.sort()\n",
        "t=t[0:5000]        \n",
        "for ii  in t:        \n",
        "        \n",
        "        v=cv2.imread(ii)\n",
        "        #v=cv2.cvtColor(v, cv2.COLOR_BGR2RGB)\n",
        "        v=cv2.cvtColor(v, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "        #v = cv2.normalize(v, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        v=cv2.resize(v,(gh,gh))\n",
        "        a.append([v])\n",
        "x=[]\n",
        "y=[]\n",
        "for f in a:\n",
        "    x.append(f)\n",
        "\n",
        "for i in  p1:\n",
        "    e=os.path.join(dirss,i)\n",
        "    \n",
        "    for j in os.listdir(e):\n",
        "        pa=os.path.join(e,j)\n",
        "    \n",
        "        r.append(pa)\n",
        "\n",
        "r.sort()        \n",
        "r=r[0:5000]       \n",
        "for ii in r:        \n",
        "        v=cv2.imread(ii)\n",
        "        \n",
        "        v = cv2.normalize(v, None, alpha=0, beta=28, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "        v=cv2.resize(v,(gh,gh))\n",
        "        v=cv2.cvtColor(v, cv2.COLOR_RGB2GRAY)\n",
        "        #v=dax(v)\n",
        "        #re,g,b=cv2.split(v)\n",
        "        #v=g  \n",
        "        #v=cv2.merge([(re*0.3+g*0.5+b*0.2)])\n",
        "        #v = np.array(v,dtype = np.uint8)  \n",
        "        aa.append([v])\n",
        "\n",
        "for l in aa:\n",
        "    \n",
        "    y.append(l)        \n",
        "x=np.array(x).reshape(-1,gh,gh,3)\n",
        "\n",
        "y=np.array(y).reshape(-1,gh,gh,1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE-c1EXg1MdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4565364d-9aa9-41ee-c02d-091b54c9cc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 128, 128, 3) (5000, 128, 128, 29)\n"
          ]
        }
      ],
      "source": [
        "print(x.shape , y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb4Jnl6x97gs"
      },
      "outputs": [],
      "source": [
        "y[0:2,0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQPz5A_Q9gvV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#pickle_out=open(\"x.pickle\",\"wb\")\n",
        "#pickle.dump(x,pickle_out,protocol=5)\n",
        "#pickle_out.close()\n",
        "pickle_out=open(\"y.pickle\",\"wb\")\n",
        "pickle.dump(y,pickle_out,protocol=5)\n",
        "pickle_out.close()\n",
        "#pickle_in=open(\"x.pickle\",\"rb\")\n",
        "#x=pickle.load(pickle_in)\n",
        "\n",
        "y=to_categorical(pickle.load(open(\"y.pickle\",\"rb\")),dtype =\"uint8\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVaDVRo-q_Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b0c2e1-8360-4ad0-a808-5a2573d10e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 128, 128, 27)\n",
            "(1500, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "print(y.shape)\n",
        "print(x.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0][0][0]"
      ],
      "metadata": {
        "id": "2hKIiQM1LE7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoxPGA1X3ww7"
      },
      "outputs": [],
      "source": [
        "v = np.array(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtHx75pCQ4Ua"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,dtype =\"uint8\")\n",
        "#pickle_out=open(\"YY.pickle\",\"wb\")\n",
        "#pickle.dump(YY,pickle_out,protocol=5)\n",
        "#pickle_out.close()\n",
        "\n",
        "\n",
        "#pickle_in=open(\"YY.pickle\",\"rb\")\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train, x_val,y_train, y_val = train_test_split(X,Y,test_size=0.000336134454, random_state=9,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Uer5XKsKkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3672b0b8-906a-41ef-cf36-e476f97a1a2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(np.unique(y[]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "EqyGCMUim7vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWRim11OcHNi"
      },
      "outputs": [],
      "source": [
        "pickle_in=open(\"YY.pickle\",\"rb\")\n",
        "YY=pickle.load(pickle_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIcwwKGTQ4Uc",
        "outputId": "d52d75cf-8f6b-48dc-8eda-d3f1f7495321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "from segmentation_models import FPN\n",
        "from segmentation_models.utils import set_trainable\n",
        "from segmentation_models.metrics import FScore\n",
        "from segmentation_models.losses import DiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXnmCX1nOqJf"
      },
      "outputs": [],
      "source": [
        "import segmentation_models as sm\n",
        "\n",
        "sm.set_framework('tf.keras')\n",
        "\n",
        "sm.framework()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT8Oke3Jwoqb"
      },
      "outputs": [],
      "source": [
        "x_train.shape,,pyramid_block_filters=320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtkujW3cQ4Ue",
        "outputId": "1db28bb5-8c50-41e2-a287-5f1ac9672ebf",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 256, 256, 3)       84        \n",
            "_________________________________________________________________\n",
            "model (Model)                multiple                  20939757  \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 29)      5510      \n",
            "=================================================================\n",
            "Total params: 20,945,351\n",
            "Trainable params: 20,817,847\n",
            "Non-trainable params: 127,504\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.compat.v1.disable_eager_execution() \n",
        "N= x.shape[-1]\n",
        "base_model =FPN(backbone_name='efficientnetb4',activation='relu',encoder_weights='imagenet')\n",
        "inp =Input(shape=(gh,gh,N))\n",
        "l1=Conv2D(3,(3,3),padding='same',activation='relu')(inp)\n",
        "\n",
        "\n",
        "out=base_model(l1)\n",
        "\n",
        "\n",
        "l2 =Conv2D(29,(3,3),padding='same',activation='softmax')(out)\n",
        "\n",
        "model=Model(inp,l2, name=base_model.name)\n",
        "\n",
        "model.summary()                                                                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTex2CvdgBV5"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3HJeMwt4LTe"
      },
      "outputs": [],
      "source": [
        "#model=tfmot.sparsity.keras.prune_low_magnitude(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in1xsRQlZ_uT"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-7\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1. - dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhUqj53lQ4Ui"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\"model-(val_loss:ww82).h5\",monitor = \"val_loss\",verbose=1,save_best_only=True,save_weigths_only=True)\n",
        "\n",
        "callback_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXlkST31Q4Ui"
      },
      "outputs": [],
      "source": [
        "ad = Adam(learning_rate=3e-4)\n",
        "model.compile(optimizer = ad, \n",
        "              loss =  dice_coef_loss,\n",
        "              metrics = [dice_coef])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIZPfcsfSr9C"
      },
      "outputs": [],
      "source": [
        "xx=np.concatenate((X[100:150],X[2000:2975],X[500:650],X[1500:1650]))\n",
        "yy=np.concatenate((Y[100:150],Y[2000:2975],Y[500:650],Y[1500:1650]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWpQNW7ofjAT"
      },
      "outputs": [],
      "source": [
        "xx=x[::4]\n",
        "yy=x[::4]\n",
        "x=np.delete(x,slice(None, None, 4), 0)\n",
        "y=np.delete(y,slice(None, None, 4), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBi4Kx6pOOp2"
      },
      "outputs": [],
      "source": [
        "def gene(x,y):\n",
        "    y= to_categorical(y,dtype =\"uint8\")\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jaq43cHdDgKJ",
        "outputId": "1e1ada0d-9c2e-4a2b-c164-ae27ed2e8141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.3001 - dice_coef: 0.6999\n",
            "Epoch 00001: val_loss improved from inf to 0.23514, saving model to model-(val_loss:ww82).h5\n",
            "4000/4000 [==============================] - 240s 60ms/sample - loss: 0.3001 - dice_coef: 0.6999 - val_loss: 0.2351 - val_dice_coef: 0.7649\n",
            "Epoch 2/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.2420 - dice_coef: 0.7580\n",
            "Epoch 00002: val_loss improved from 0.23514 to 0.22601, saving model to model-(val_loss:ww82).h5\n",
            "4000/4000 [==============================] - 230s 58ms/sample - loss: 0.2421 - dice_coef: 0.7579 - val_loss: 0.2260 - val_dice_coef: 0.7740\n",
            "Epoch 3/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.2240 - dice_coef: 0.7760\n",
            "Epoch 00003: val_loss improved from 0.22601 to 0.21980, saving model to model-(val_loss:ww82).h5\n",
            "4000/4000 [==============================] - 230s 57ms/sample - loss: 0.2241 - dice_coef: 0.7759 - val_loss: 0.2198 - val_dice_coef: 0.7802\n",
            "Epoch 4/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.2141 - dice_coef: 0.7859\n",
            "Epoch 00004: val_loss did not improve from 0.21980\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.2140 - dice_coef: 0.7860 - val_loss: 0.2240 - val_dice_coef: 0.7760\n",
            "Epoch 5/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.2031 - dice_coef: 0.7969\n",
            "Epoch 00005: val_loss improved from 0.21980 to 0.21756, saving model to model-(val_loss:ww82).h5\n",
            "4000/4000 [==============================] - 230s 57ms/sample - loss: 0.2032 - dice_coef: 0.7968 - val_loss: 0.2176 - val_dice_coef: 0.7824\n",
            "Epoch 6/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1953 - dice_coef: 0.8047\n",
            "Epoch 00006: val_loss did not improve from 0.21756\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.1953 - dice_coef: 0.8047 - val_loss: 0.2520 - val_dice_coef: 0.7480\n",
            "Epoch 7/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1839 - dice_coef: 0.8161\n",
            "Epoch 00007: val_loss did not improve from 0.21756\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.1838 - dice_coef: 0.8162 - val_loss: 0.2176 - val_dice_coef: 0.7824\n",
            "Epoch 8/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1800 - dice_coef: 0.8200\n",
            "Epoch 00008: val_loss improved from 0.21756 to 0.21439, saving model to model-(val_loss:ww82).h5\n",
            "4000/4000 [==============================] - 230s 58ms/sample - loss: 0.1798 - dice_coef: 0.8202 - val_loss: 0.2144 - val_dice_coef: 0.7856\n",
            "Epoch 9/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1689 - dice_coef: 0.8311\n",
            "Epoch 00009: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.1689 - dice_coef: 0.8311 - val_loss: 0.2153 - val_dice_coef: 0.7847\n",
            "Epoch 10/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1617 - dice_coef: 0.8383\n",
            "Epoch 00010: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.1616 - dice_coef: 0.8384 - val_loss: 0.2221 - val_dice_coef: 0.7779\n",
            "Epoch 11/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1536 - dice_coef: 0.8464\n",
            "Epoch 00011: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 228s 57ms/sample - loss: 0.1536 - dice_coef: 0.8464 - val_loss: 0.2228 - val_dice_coef: 0.7772\n",
            "Epoch 12/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1546 - dice_coef: 0.8454\n",
            "Epoch 00012: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 228s 57ms/sample - loss: 0.1546 - dice_coef: 0.8454 - val_loss: 0.2148 - val_dice_coef: 0.7852\n",
            "Epoch 13/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1479 - dice_coef: 0.8521\n",
            "Epoch 00013: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 228s 57ms/sample - loss: 0.1478 - dice_coef: 0.8522 - val_loss: 0.2266 - val_dice_coef: 0.7734\n",
            "Epoch 14/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1436 - dice_coef: 0.8564\n",
            "Epoch 00014: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 228s 57ms/sample - loss: 0.1435 - dice_coef: 0.8565 - val_loss: 0.2248 - val_dice_coef: 0.7752\n",
            "Epoch 15/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1413 - dice_coef: 0.8587\n",
            "Epoch 00015: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 229s 57ms/sample - loss: 0.1412 - dice_coef: 0.8588 - val_loss: 0.2150 - val_dice_coef: 0.7850\n",
            "Epoch 16/160\n",
            "3992/4000 [============================>.] - ETA: 0s - loss: 0.1360 - dice_coef: 0.8640\n",
            "Epoch 00016: val_loss did not improve from 0.21439\n",
            "4000/4000 [==============================] - 228s 57ms/sample - loss: 0.1362 - dice_coef: 0.8638 - val_loss: 0.2280 - val_dice_coef: 0.7720\n",
            "Epoch 17/160\n",
            " 184/4000 [>.............................] - ETA: 3:22 - loss: 0.1553 - dice_coef: 0.8447"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6b147959ae71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3567\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3568\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1473\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "h=model.fit(x=x,y=y, shuffle=True,batch_size = 8 ,validation_split=0.2, epochs=160,callbacks = callback_list,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTOtE7ZWQ4Uj"
      },
      "source": [
        "h=model.fit(datagen.flow(x_train, y_train,=32,subset='training'),validation_data=datagen.flow(x_train, y_train, batch_size=32,subset='validation'),steps_per_epoch=100 ,validation_steps=100, epochs=10,callbacks = callback_list,shuffle=True,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aHDERXFJeGG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYMoOGGN1OMX"
      },
      "outputs": [],
      "source": [
        "model.save('model-(val_loss:wffw82).h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYlI0l73-98I"
      },
      "outputs": [],
      "source": [
        "a=X[0:25].append(X[50:75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpeUZR2EbLjm"
      },
      "outputs": [],
      "source": [
        "px = h.history['loss']\n",
        "py = h.history['val_dice_coef']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ozFvQyCwXo_"
      },
      "outputs": [],
      "source": [
        "plt.plot(py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32CntQDQJK_y"
      },
      "outputs": [],
      "source": [
        "model=load_model('/content/model-(val_loss:ww82).h5',compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HafOWf_QHKYH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_val,y_val,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL2v8EcZQ4Um"
      },
      "outputs": [],
      "source": [
        "predict_train = model.predict(x_train[435:440],verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkN09pmkW37F"
      },
      "outputs": [],
      "source": [
        "l = np.argmax(predict_train, axis=-1)\n",
        "l.reshape(5,64,64,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl2aIsmLnIKj"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x[300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "9wesabbhpk5W",
        "outputId": "8df9f4ba-32da-4844-98c6-0e23e05b3cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0e7295d5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "te=x[2000]\n",
        "#te=te[0:300,0:250]\n",
        "#te=cv2.resize(te,(320,320))\n",
        "ert=np.array([te])\n",
        "predict_train = model.predict(ert,verbose=2)\n",
        "l = np.argmax(predict_train[0], axis=-1)\n",
        "l.reshape(1,gh,gh,1)\n",
        "asd1 = np.array(l)\n",
        "asd = np.array(asd1*8,dtype = np.uint8)\n",
        "#xpx =cv2.merge([asd,asd ,asd])\n",
        "xpx=cv2.applyColorMap(asd, cv2.COLORMAP_HSV)\n",
        "\n",
        "xpx=cv2.cvtColor(xpx, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(xpx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-sY5gNUA7x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224bac26-f466-44eb-d992-9433ccf47511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "asd1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylb_iA2-xKiC"
      },
      "outputs": [],
      "source": [
        "from astropy.visualization import make_lupton_rgb\n",
        "bb= np.array(xpx,dtype=np.float64)\n",
        "re,g,b=cv2.split(bb)\n",
        "image = make_lupton_rgb(re/5, g/3, b/8, stretch=0.5)\n",
        "plt.imshow(image/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CegKpIJNCwYU"
      },
      "outputs": [],
      "source": [
        "bb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9G5fgU8Q4Uo"
      },
      "outputs": [],
      "source": [
        "asd11 = cv2.imread('/content/GDrive/MyDrive/ims/1022.png')\n",
        "gh =192\n",
        "asd1=cv2.cvtColor(asd11, cv2.COLOR_BGR2RGB)\n",
        "asd1 = cv2.normalize(asd1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "d1=asd11\n",
        "asd01=cv2.resize(asd1,(gh,gh))\n",
        "asd1 = np.array([asd01]).reshape(-1,gh,gh,3)\n",
        "asd = model.predict(asd1)\n",
        "#asd = np.argmax(asd, axis=-1)\n",
        "#asd=asd.reshape(1,gh,gh,1)\n",
        "#asd = np.array(asd[0])\n",
        "#xpx =cv2.merge([asd,asd,asd])\n",
        "plt.imshow(asd[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTmi5qu8VjJu"
      },
      "outputs": [],
      "source": [
        "plt.imshow(asd01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrDi86rthgv3"
      },
      "outputs": [],
      "source": [
        "!pip install Js2Py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anGq1pzClhbo"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import js2py\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLUCSea9lgGv"
      },
      "outputs": [],
      "source": [
        "!pip install requires.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-moHnxlxjb5T"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import io\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGB')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhrCfP3xQ9bU"
      },
      "outputs": [],
      "source": [
        "gh=320\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,3], dtype=np.uint8)\n",
        "\n",
        "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "    n =frame\n",
        "    frame=np.array(frame)\n",
        "    #frame=cv2.resize(frame,(720,960))\n",
        "    frame=cv2.resize(frame,(gh,gh))\n",
        "    #frame=cv2.medianBlur(frame,5) \n",
        "    frame=np.array([frame],dtype=np.float32).reshape(-1,gh,gh,3)\n",
        "    predict_v= model.predict(frame,workers=320,use_multiprocessing=True) \n",
        "    \n",
        "    #l = np.argmax(predict_v, axis=-1)\n",
        "    #l.reshape(1,gh,gh,1)\n",
        "    #xpx =cv2.merge([l[0],l[0],l[0]])\n",
        "    #vv = xpx/255\n",
        "    #vv=np.array(vv, dtype=np.float32)\n",
        "           \n",
        "    vv=cv2.resize(predict_v[0],(640,480))\n",
        "    #fr=cv2.GaussianBlur(vv,(51,51),2)\n",
        "    #vv=cv2.addWeighted(vv,2,fr,-1,4)\n",
        "    vv=cv2.cvtColor(vv/255, cv2.COLOR_BGR2RGB)\n",
        "    vv=cv2.medianBlur(vv,5)\n",
        "    #vv=np.array([vv],dtype=np.float32)\n",
        "    #vv[:,:,3] = (vv.max(axis =2) > 0 ).astype(int)*255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(vv)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5etJXgOq7Qb"
      },
      "outputs": [],
      "source": [
        "frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ2lzREkga08"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while(cap.isOpened()):\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    gray1 = frame\n",
        "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    l1= np.array([20,133,67],np.uint8)\n",
        "    u1= np.array([205,163,127],np.uint8)\n",
        "    l2= np.array([7,110,100],np.uint8)\n",
        "    u2= np.array([205,163,135],np.uint8)\n",
        "    mask1=cv2.inRange(frame,l1,u1)\n",
        "    mask2=cv2.inRange(frame,l2,u2)\n",
        "   \n",
        "    mass = mask1          \n",
        "           \n",
        "    cv2.imshow('test', mass)\n",
        "    cv2.imshow('dfg',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DmaPSrV8HQS"
      },
      "source": [
        "import os \n",
        "\n",
        "class satyam :\n",
        "    def __init__(self,a = 56 ,b= 85 ):\n",
        "        self.j=a\n",
        "        self.h=b\n",
        "    def get(self):\n",
        "        return self.j + self.h\n",
        "    def ty(self):\n",
        "       \n",
        "        pass\n",
        "    def __add__(self,other):\n",
        "        return self.h * other.h    \n",
        "       \n",
        "class er(satyam):\n",
        "    def __init__(self,a= 2, b =23):\n",
        "        \n",
        "       super().__init__(a,b)  \n",
        "\n",
        "satyam.a=0\n",
        "s=satyam()\n",
        "print(s.get())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBo2c8DoDoqT"
      },
      "outputs": [],
      "source": [
        "t=Y[463: ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jJR_KRJBDnS"
      },
      "outputs": [],
      "source": [
        "label = [0,1,1,0]\n",
        "label = tf.keras.utils.to_categorical(label,3)\n",
        "print(label) #output: label = [[1,0],[0,1],[0,1],[1,0]]\n",
        "\n",
        "print(label) #output back to [0,1,1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Aj723mEhWt"
      },
      "outputs": [],
      "source": [
        "label = tf.keras.utils.to_categorical(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_-GuIxfF6Ki"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBBc-I4CBuB0"
      },
      "outputs": [],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN5lFCd2PQTM"
      },
      "outputs": [],
      "source": [
        "np.argmax([predict_val[195]],axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czpvUv-fKkyi"
      },
      "outputs": [],
      "source": [
        "y_binary[0][0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nrRZmu-OLzD"
      },
      "outputs": [],
      "source": [
        "plt.imshow(y_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzybd7p2LZTP"
      },
      "outputs": [],
      "source": [
        "label = np.argmax(t, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcvjhW4RMbtL"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNXCJsWLNFNu"
      },
      "outputs": [],
      "source": [
        "label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZWUna6DLjvH"
      },
      "outputs": [],
      "source": [
        "label[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cma_667eMhlY"
      },
      "outputs": [],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkdQ4mjjIDsy"
      },
      "outputs": [],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUuAiRyWI1OF"
      },
      "outputs": [],
      "source": [
        "l = np.argmax(y_val, axis=-1)\n",
        "l.reshape(100,128,128,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkkKCtIeWfAJ"
      },
      "outputs": [],
      "source": [
        "l=cv2.cvtColor(l[0], cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VylhMVMPtpMx"
      },
      "outputs": [],
      "source": [
        "YY"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of Untitled122.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}